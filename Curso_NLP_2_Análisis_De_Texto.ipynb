{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Curso NLP 2 An√°lisis De Texto",
      "provenance": [],
      "collapsed_sections": [
        "X5PKzi_s2dOK",
        "iskIFXoKOHWJ",
        "CbnHNtDZwtJJ",
        "-jMcxMRqO_JB",
        "Mh8Bw-ueLCUh",
        "U2N2LXmi3Bpc",
        "0nC5Vnqfd2aP",
        "8rXB5QLG4I8n",
        "c_9GEv-mZUps",
        "mrrZMSs34_4y",
        "iq09LfuQdj6I",
        "2FMiGzj5t4wK",
        "VcGGUC0Zv7Lc",
        "mkOPiFSGvK2v",
        "WR0aunRfWI1Q",
        "LfaQ0CCWRg98",
        "WZ9vPMGWHul3",
        "b3ouxnMzIBrc",
        "ESxDbEKzeuyo",
        "1yaNheu71Ijz",
        "jqJis2fsgFtX",
        "7szhw-XfR1ez",
        "4tkaONJNTmYA",
        "AHgF-ScaU3M3",
        "dOgDBKm_h8Eq",
        "FVP62uKbKUvR",
        "Kpj95PziKQb0",
        "wyTU548Z5eGA",
        "rz_kcafdIav2",
        "7JmzySfGP48w"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armandovl/curso_nlp/blob/main/Curso_NLP_2_An%C3%A1lisis_De_Texto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1pVlXCyGL4c"
      },
      "source": [
        "<img src=\"https://i1.wp.com/www.sopitas.com/wp-content/uploads/2014/08/Tec-de-Monterrey-Logo-640x581.jpg\" width=\"70\"/> \n",
        "<h5>ITESM Campus Santa Fe <br> Armando Vald√©s </h5>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5PKzi_s2dOK"
      },
      "source": [
        "### Nomenclatura\n",
        "üü† Modificar <br>\n",
        "‚èÆ Repetir en caso de cambiar texto<br>\n",
        "üîò Opcional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iskIFXoKOHWJ"
      },
      "source": [
        "###  **1.-Importar el archivo** üü† "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aquh7m6VKH2A"
      },
      "source": [
        "#1#\n",
        "#lo primero que hacemos es importar el archivo de texto, en r de reescribir\n",
        "archivo=open(\"buenos_soluble.txt\",\"r\")\n",
        "texto_del_archivo=archivo.read() #el texto del txt se queda en la variable texto_del_archivo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbnHNtDZwtJJ"
      },
      "source": [
        "### **2.-Importar bibliotecas**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jMcxMRqO_JB"
      },
      "source": [
        "#### Cargar NLTK <br>\n",
        "TOKENIZACION, ELIMINAR STOP WORDS, DERIVACI√ìN <BR>\n",
        "GRAFICAR Y EXPORTAR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anIBKo8TO-A_"
      },
      "source": [
        "#2#\n",
        "import nltk #importamos nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQh_337xP-xH"
      },
      "source": [
        "#3#\n",
        "nltk.download('punkt') #parte para tokenizar\n",
        "nltk.download('stopwords') #parte para stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mh8Bw-ueLCUh"
      },
      "source": [
        "#### Cargar SPACY <br>\n",
        "VERBOS, ADJETIVOS,LEMATIZACION, SUSTANTIVOS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEbPb4BOOXuC"
      },
      "source": [
        "#4#\n",
        "#!pip install spacy #NO ES NECESARIO PERO POR SI SE TIENE QUE INSTALAR\n",
        "import spacy "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WERpB0BWPCP-"
      },
      "source": [
        "#5#\n",
        "#Descargar librer√≠a\n",
        "!python -m spacy download es_core_news_sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7JVQg4bPORU"
      },
      "source": [
        "#6#\n",
        "#cargar libreria espa√±ol\n",
        "#SI NO CARGA HAY QUE EJECUTAR TODO DE NUEVO\n",
        "nlp= spacy.load('es_core_news_sm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPjfUw-PrRnM"
      },
      "source": [
        "#7# una vez que se ejecute todo se comenta este c√≥digo\n",
        "print(detener) #la uso para detener el ejecutar todo de nuevo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2N2LXmi3Bpc"
      },
      "source": [
        "### **3.- Crear funciones**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nC5Vnqfd2aP"
      },
      "source": [
        "#### Funcion tokenizar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5pMQKSMQM0U"
      },
      "source": [
        "#8#\n",
        "#Funcion Tokenizar\n",
        "def tokenizar(texto_para_tonekizar):\n",
        "  from nltk.tokenize import word_tokenize #importar la parte tokenizadora\n",
        "  salida_funcion_tok = word_tokenize(texto_para_tonekizar,\"spanish\") #secciona o tokeniza\n",
        "  salida_funcion_tok =[word.lower() for word in salida_funcion_tok if word.isalpha()] # Remover los signos de puntuaci√≥n\n",
        "  return(salida_funcion_tok)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNo8_PMh4wkb"
      },
      "source": [
        "üîò Ejemplo tokenizaci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e0iFwmV4tAd"
      },
      "source": [
        "textoEjemplo=tokenizar(\"Este es el texto para tokenizar\")\n",
        "print(textoEjemplo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rXB5QLG4I8n"
      },
      "source": [
        "#### Funcion Quitar Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lGw2oPaZCJN"
      },
      "source": [
        "#9#\n",
        "#Funcion Quitar Stop Words\n",
        "def quitarStopWords(texto_para_quitar_stop_words):\n",
        "  from nltk.corpus import stopwords\n",
        "  salida_sin_stop_words = texto_para_quitar_stop_words[:]\n",
        "  for token in texto_para_quitar_stop_words:\n",
        "     if token in stopwords.words('spanish'):\n",
        "         salida_sin_stop_words.remove(token)\n",
        "  return(salida_sin_stop_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccNodd_G5lB0"
      },
      "source": [
        "üîò Ejemplo Quitar Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8m2ZN0H52G3"
      },
      "source": [
        "textoEjemplo2=\"en el agua clara que brota en la fuente\"\n",
        "textoEjemplo2Tokenizado=tokenizar(textoEjemplo2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDB7lwxF6qwu"
      },
      "source": [
        "textoEjemplo2Tokenizado"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIiwEVgQ6U-F"
      },
      "source": [
        "texto_Ejemplo2_Sin_Stopwords=quitarStopWords(textoEjemplo2Tokenizado)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOAxebDm6ubP"
      },
      "source": [
        "texto_Ejemplo2_Sin_Stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_9GEv-mZUps"
      },
      "source": [
        "#### Funcion Lematizar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lYFdMAHTii_"
      },
      "source": [
        "#10#\n",
        "def lematizar(texto_a_lematizar):\n",
        "  texto_lematizado = []\n",
        "  separator = ' '\n",
        "  for token in nlp(separator.join(texto_a_lematizar)): #Se juntan los tokens en una string, string es el formato necesario para nlp\n",
        "    #print(token.text, token.lemma_, token.pos_)\n",
        "    texto_lematizado.append(token.lemma_)\n",
        "  return(texto_lematizado)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEptQ1Mh7pNd"
      },
      "source": [
        "üîò Ejemplo Lematizar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boEBJVqp7r0t"
      },
      "source": [
        "textoEjemplo3=[\"estudiar\",\"estudioso\",\"estudia\",\"estudio\",\"estudiando\",\"estudiante\",\"estudiaba\",\"estudi√≥\"]\n",
        "ejemplo3_texto_lematizado=lematizar(textoEjemplo3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmBmcQO-8J83"
      },
      "source": [
        "contador=0\n",
        "for i in textoEjemplo3:\n",
        "  print(textoEjemplo3[contador],\"->\", ejemplo3_texto_lematizado[contador])\n",
        "  contador=contador+1\n",
        "  #no cambi√≥ el adjetivo ni el sustantivo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLMm3ksfDOaz"
      },
      "source": [
        "print(textoEjemplo3)\n",
        "print(ejemplo3_texto_lematizado) #no cambi√≥ adjetivo y sustantivo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrrZMSs34_4y"
      },
      "source": [
        "#### Funci√≥n Derivaci√≥n Regresiva"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU_--aSF5K_l"
      },
      "source": [
        "#11#\n",
        "def derivar_texto(texto_a_derivar):\n",
        "  salida_texto_derivado=[]\n",
        "  from nltk.stem import SnowballStemmer\n",
        "  derivar=SnowballStemmer(\"spanish\")\n",
        "  for derv in texto_a_derivar:\n",
        "    salida_texto_derivado.append(derivar.stem(derv))\n",
        "  return(salida_texto_derivado)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7ttdPPkDZ_n"
      },
      "source": [
        "üîò Ejemplo derivaci√≥n regresiva"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgeHyRfC-UfZ"
      },
      "source": [
        "textoEjemplo4=[\"estudiar\",\"estudioso\",\"estudia\",\"estudio\",\"estudiando\",\"estudiante\",\"estudiaba\",\"estudi√≥\"]\n",
        "texto_derivado = derivar_texto(textoEjemplo4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TqJOvoL-3gb"
      },
      "source": [
        "contador=0\n",
        "for i in textoEjemplo4:\n",
        "  print(textoEjemplo4[contador],\"->\", texto_derivado[contador])\n",
        "  contador=contador+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iq09LfuQdj6I"
      },
      "source": [
        "#### Funciones para Graficar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfcG5GeHeGaE"
      },
      "source": [
        "#12#\n",
        "import matplotlib.pyplot as plt #importamos para graficos\n",
        "import seaborn as sns #importamos para graficos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kg66qRiD_knU"
      },
      "source": [
        "Gr√°fico de barras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysKwkVZIeVR_"
      },
      "source": [
        "#13#\n",
        "def graficarBarras(texto_a_graficar, palabras_top):\n",
        "  frecuencia = nltk.FreqDist(texto_a_graficar) #obtener las frecuencias\n",
        "  minimo_palabras_adjetivos=frecuencia.most_common(palabras_top) #hacemos una lista de los top 20\n",
        "  x,y=zip(*minimo_palabras_adjetivos)\n",
        "  plt.figure(figsize=(10, 7)) #largo vs ancho\n",
        "  plt.barh(x,y)\n",
        "  \n",
        "  #cambiar axis\n",
        "  ax = plt.gca()\n",
        "  ax.set_ylim(ax.get_ylim()[::-1])\n",
        "  ax=plt.xlabel(\"Fecuencia de Palabras\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-xdQMzNCjC6"
      },
      "source": [
        "#üîò\n",
        "ejemplo5_texto= [\"gato\",\"perro\",\"perico\",\"gato\",\"gato\",\"perico\",\"caballo\",\"perico\",\"perico\",\"rana\"]\n",
        "graficarBarras(ejemplo5_texto,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFn3TN8o_r27"
      },
      "source": [
        "Gr√°fico de nube"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUZ2gpIxgSxi"
      },
      "source": [
        "#14#\n",
        "def graficarNube(texto_a_graficar):\n",
        "  from wordcloud import WordCloud\n",
        "  frecuencia = nltk.FreqDist(texto_a_graficar)\n",
        "  filter_words = dict([(m, n) for m, n in frecuencia.items() if len(m) > 3])\n",
        "  wcloud = WordCloud(background_color=\"White\").generate_from_frequencies(filter_words)\n",
        "  # Plotting the wordcloud\n",
        "  plt.figure(figsize=(9, 9))\n",
        "  plt.imshow(wcloud, interpolation=\"bilinear\")\n",
        "  plt.axis(\"off\")\n",
        "  (-0.5, 399.5, 300.5, -0.5)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JnUOpVwDY-c"
      },
      "source": [
        "#üîò\n",
        "ejemplo5_texto= [\"gato\",\"perro\",\"perico\",\"gato\",\"gato\",\"perico\",\"caballo\",\"perico\",\"perico\",\"rana\"]\n",
        "graficarNube(ejemplo5_texto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FMiGzj5t4wK"
      },
      "source": [
        "#### Funci√≥n para quitar una palabra de una lista"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBWqdW4Rud98"
      },
      "source": [
        "#15#\n",
        "#remover palabra\n",
        "def removerPalabra(texto_a_quitar,palabra_a_remover):\n",
        "  conteo=texto_a_quitar.count(palabra_a_remover)\n",
        "  for elim in range(0,conteo):\n",
        "    texto_a_quitar.remove(palabra_a_remover)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMfZvoGTD_Yr"
      },
      "source": [
        "üîò Ejemplo quitar Palabra"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2GzOIw3DtcZ"
      },
      "source": [
        "ejemplo5_texto= [\"gato\",\"perro\",\"perico\",\"gato\",\"gato\",\"perico\",\"caballo\",\"perico\",\"perico\",\"rana\"]\n",
        "removerPalabra(ejemplo5_texto,\"gato\")\n",
        "ejemplo5_texto"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcGGUC0Zv7Lc"
      },
      "source": [
        "#### Funci√≥n para reemplazar una palabra de una lista"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_qC1GkrspIW"
      },
      "source": [
        "#15#\n",
        "#reemplazar palabra\n",
        "def reemplazarPalabra(texto_a_reemplazar,palabra_a_reemplazar,palabra_para_reemplazar):\n",
        "  conteo=texto_a_reemplazar.count(palabra_a_reemplazar)\n",
        "  for elim in range(0,conteo):\n",
        "    #esta solita me remplaza palabras\n",
        "    texto_a_reemplazar=[sub.replace(palabra_a_reemplazar,palabra_para_reemplazar) for sub in texto_a_reemplazar]\n",
        "    ######\n",
        "    return texto_a_reemplazar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFgI9_gz5SPa"
      },
      "source": [
        "üîò Ejemplo reemplazar palabras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImRbCYEtuDKo"
      },
      "source": [
        "ejemplo6_texto= [\"gato\",\"perro\",\"perico\",\"gato\",\"gato\",\"perico\",\"caballo\",\"perico\",\"perico\",\"rana\"]\n",
        "#ejemplo6_texto=[sub.replace('gato', 'cat0') for sub in ejemplo6_texto]\n",
        "ejemplo6_texto=reemplazarPalabra(ejemplo6_texto,\"gato\",\"cato\")\n",
        "ejemplo6_texto"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkOPiFSGvK2v"
      },
      "source": [
        "#### Funci√≥n expotar a csv con frecuencia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBrD-v7iysuL"
      },
      "source": [
        "#16#\n",
        "def exportarLista(lista_a_exportar, nombre_archivo_csv):\n",
        "  #hacemos un diccioneario con las frecuencias\n",
        "  from collections import Counter\n",
        "  contador = Counter(lista_a_exportar)\n",
        "\n",
        "  #lo transformamos en un dataframe\n",
        "  import pandas as pd #importamos la biblioteca\n",
        "  dataframe=pd.DataFrame.from_dict(contador,orient='index').reset_index()\n",
        "\n",
        "  #exportamos a csv\n",
        "  dataframe.columns=[\"palabra\",\"frecuencia\"]\n",
        "  dataframe.to_csv(nombre_archivo_csv, index=False, encoding='utf-8')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR0aunRfWI1Q"
      },
      "source": [
        "#### Funci√≥n expotar varias listas a csv con frecuencia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvOFzk94WJII"
      },
      "source": [
        "#16.1#\n",
        "def exportarListaCompleta(lista_a_exportar1,lista_a_exportar2,lista_a_exportar3, nombre_archivo_csv):\n",
        "  #hacemos un diccioneario con las frecuencias\n",
        "  from collections import Counter\n",
        "\n",
        "  contador1 = Counter(lista_a_exportar1)\n",
        "  contador2 = Counter(lista_a_exportar2)\n",
        "  contador3 = Counter(lista_a_exportar3)\n",
        "\n",
        "  #lo transformamos en un dataframe\n",
        "  import pandas as pd #importamos la biblioteca\n",
        "\n",
        "  df1=pd.DataFrame.from_dict(contador1,orient='index').reset_index()\n",
        "  df1.columns=[\"palabra1\",\"frecuencia1\"]\n",
        "\n",
        "  df2=pd.DataFrame.from_dict(contador2,orient='index').reset_index()\n",
        "  df2.columns=[\"palabra2\",\"frecuencia2\"]\n",
        "\n",
        "  df3=pd.DataFrame.from_dict(contador3,orient='index').reset_index()\n",
        "  df3.columns=[\"palabra3\",\"frecuencia3\"]\n",
        "\n",
        "  lista44=[\" \",\" \", \" \"]\n",
        "  df44=pd.DataFrame(lista44)\n",
        "  \n",
        "  #ordenar descente\n",
        "  #df1=df1.sort_values(\"frecuencia1\",ascending=False)\n",
        "  #df2=df2.sort_values(\"frecuencia2\",ascending=False)\n",
        "  #df3=df3.sort_values(\"frecuencia3\",ascending=False)\n",
        "\n",
        "  #unir los dataframe\n",
        "  df_unido=pd.concat([df1,df44,df2,df44,df3],axis=1,ignore_index=False)\n",
        "\n",
        "\n",
        "  #exportamos a csv\n",
        "  df_unido.to_csv(nombre_archivo_csv, index=False, encoding='utf-8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfaQ0CCWRg98"
      },
      "source": [
        "###  **4.-Trabajar el texto** ‚èÆ\n",
        "Tonenizar -> Quitar StopWords -> Lematizar o Derivar <br>\n",
        "Graficar -> Exportar CSV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZ9vPMGWHul3"
      },
      "source": [
        "####  ‚èÆ 4.1.-Tokenizar el texto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0-k-LME0Z8P"
      },
      "source": [
        "#17#\n",
        "texto_tokenizado=tokenizar(texto_del_archivo) #tokenizar el texto"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3ouxnMzIBrc"
      },
      "source": [
        "#### ‚èÆ  4.2.-Quitar Stop Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wmgXGgpaLG8"
      },
      "source": [
        "#18#\n",
        "texto_sin_stop=quitarStopWords(texto_tokenizado) #texto si stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESxDbEKzeuyo"
      },
      "source": [
        "#### ‚èÆ 4.3.-Lematizacion de listas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF11t600e0hh"
      },
      "source": [
        "#19#\n",
        "texto_ya_lematizado= lematizar(texto_sin_stop)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yaNheu71Ijz"
      },
      "source": [
        "#### ‚èÆ 4.3.- Derivaci√≥n Regresiva"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDqst5_v1E9x"
      },
      "source": [
        "#20\"\n",
        "texto_ya_derivado=derivar_texto(texto_ya_lematizado) #se puede aplicar directamente a texto_sin_stop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqJis2fsgFtX"
      },
      "source": [
        "### **5.-Aplicar Spacy** ‚èÆ \n",
        "Verbos, Adejtivos, Sustantivos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bygeDez14Ndr"
      },
      "source": [
        "‚èÆ Aplicar Spacy al Texto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTb5HrqmRI6J"
      },
      "source": [
        "#21#\n",
        "doc = nlp(texto_del_archivo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7szhw-XfR1ez"
      },
      "source": [
        "#### ‚èÆ Obtener Adjetivos <br>\n",
        "Se obtiene la lista **\"adjetivoss\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK9w9e29SFn2"
      },
      "source": [
        "#22#\n",
        "adjetivoss=[token.lemma_ for token in doc if token.pos_ == \"ADJ\"] #estan lematizados"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tkaONJNTmYA"
      },
      "source": [
        "#### ‚èÆ Obtener Verbos\n",
        "Se obtiene la lista **\"verboss\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBxhqRzvTq48"
      },
      "source": [
        "#23#\n",
        "verboss=[token.lemma_ for token in doc if token.pos_ == \"VERB\"] #estan lematizados"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHgF-ScaU3M3"
      },
      "source": [
        "#### ‚èÆ Obtener Sustantivos <br>\n",
        "Se obtiene la lista **\"sustantivoss\"**\n",
        "<BR> exportar para la asociaci√≥n <br>\n",
        "convendr√≠a lematizar y/o derivar los sustantivos <br>\n",
        "lo ideal es obtener  sinonimos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkXA4xcIWGTz"
      },
      "source": [
        "#24#\n",
        "#sustantivos\n",
        "sustantivo=[]\n",
        "for noun in doc.noun_chunks:\n",
        "  sustantivo.append(noun)\n",
        "\n",
        "#unir en string\n",
        "separator = ','\n",
        "sustantivo_string=', '.join([str(x) for x in sustantivo])\n",
        "\n",
        "sustantivos_tokenizados=tokenizar(sustantivo_string)\n",
        "sustantivoss=quitarStopWords(sustantivos_tokenizados)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOgDBKm_h8Eq"
      },
      "source": [
        "### **6.-Espacio libre para trabajar** üü† <br>\n",
        "SALIDAS: <br>\n",
        "texto_sin_stop <br> \n",
        "texto_ya_lematizado <br> \n",
        "texto_ya_derivado <br> \n",
        "adjetivoss <br> \n",
        "verboss  <br> \n",
        "sustantivoss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeCP9Ven8t_Q"
      },
      "source": [
        "Funciones: <br>\n",
        "nombre_final= lematizar(texto_a_lematizar) <br>\n",
        "nombre_final=derivar_texto(texto_a_derivar) <br>\n",
        "**graficarBarras(texto_a_graficar,palabras_top) <br>\n",
        "**graficarNube(texto_a_graficar) <br>\n",
        "**removerPalabra(texto_a_quitar,\"palabra_a_remover\")<br>\n",
        "**exportarLista(adjetivoss,\"nombre_del_archivo.csv\") <br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlR57Hy37c2I"
      },
      "source": [
        "#nombre_final= lematizar(texto_a_lematizar)\n",
        "#nombre_final=derivar_texto(texto_a_derivar)\n",
        "#graficarBarras(texto_a_graficar,palabras_top)\n",
        "#graficarNube(texto_a_graficar)\n",
        "#removerPalabra(texto_a_quitar,\"palabra_a_remover\")\n",
        "#exportarLista(lista_a_exportar,\"nombre_del_archivo\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVP62uKbKUvR"
      },
      "source": [
        "###### üü† 6.1-Generar Gr√°ficos y Exportar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JEpM3g9hrYq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "676205df-8c17-418f-f176-2cadfa1bc6a1"
      },
      "source": [
        "#graficarBarras(lista a graficar, Numero top)\n",
        "graficarBarras(adjetivoss,30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6ce51a117aae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#graficarBarras(lista a graficar, Numero top)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgraficarBarras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjetivoss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'graficarBarras' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tRsETYzfwBj"
      },
      "source": [
        "#graficarNube(lista a graficar)\n",
        "graficarNube(verboss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTNWmKGY2wU-"
      },
      "source": [
        "#reemplazar r√°pida\n",
        "adjetivoss=[sub.replace('cafetero', 'cat0') for sub in adjetivoss]\n",
        "adjetivoss=[sub.replace('cafetero', 'cat0') for sub in adjetivoss]\n",
        "adjetivoss=[sub.replace('cafetero', 'cat0') for sub in adjetivoss]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kpj95PziKQb0"
      },
      "source": [
        "#####  üü†  6.2 Remover palabras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKCbzagWvvI3"
      },
      "source": [
        "#üîò removerPalabra(texto de donde se remover√°,\"palabra a remover\")\n",
        "removerPalabra(adjetivoss,\"bueno\")\n",
        "removerPalabra(adjetivoss,\"Excelente\")\n",
        "removerPalabra(adjetivoss,\"rico\")\n",
        "removerPalabra(adjetivoss,\"excelente\")\n",
        "removerPalabra(adjetivoss,\"delicioso\")\n",
        "removerPalabra(adjetivoss,\"Buen\")\n",
        "removerPalabra(adjetivoss,\"mejor\")\n",
        "removerPalabra(adjetivoss,\"recomendable\")\n",
        "removerPalabra(adjetivoss,\"perfecto\")\n",
        "removerPalabra(adjetivoss,\"agradable\")\n",
        "removerPalabra(adjetivoss,\"Bueno\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyTU548Z5eGA"
      },
      "source": [
        "#####  üü†  6.3 Reemplazar palabras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H02KwY_r5oEq"
      },
      "source": [
        "#forma uno para reemplazar\n",
        "adjetivoss=[sub.replace('compatible', 'incompatible') for sub in adjetivoss] \n",
        "adjetivoss=[sub.replace('cafetero', 'cat0') for sub in adjetivoss]\n",
        "adjetivoss=[sub.replace('cafetero', 'cat0') for sub in adjetivoss]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s3J8akq5zmc"
      },
      "source": [
        "adjetivoss=reemplazarPalabra(adjetivoss,\"palabra a reemplazar\",\"palabra para reemplazar\") #otra forma de reemplazar\n",
        "adjetivoss=reemplazarPalabra(adjetivoss,\"palabra a reemplazar\",\"palabra para reemplazar\") #otra forma de reemplazar\n",
        "adjetivoss=reemplazarPalabra(adjetivoss,\"palabra a reemplazar\",\"palabra para reemplazar\") #otra forma de reemplazar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJ4eMqtF5pJ_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz_kcafdIav2"
      },
      "source": [
        "#####   üü†  6.4 Exportar lista a csv con frecuencias \n",
        "Importante!! <br>\n",
        "Servir√° para Asociaci√≥n con vectores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewP9Kh2N38UV"
      },
      "source": [
        "#üîò exportarLista(texto para exportar, nombre del nuevo archivo)\n",
        "exportarLista(texto_sin_stop,\"frecuencia_solubles_malo.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JmzySfGP48w"
      },
      "source": [
        "#####   üü†  6.5 Exportar varias listas a csv con frecuencias \n",
        "Importante!! <br>\n",
        "Servir√° para Asociaci√≥n con vectores\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZBZIsnaPq2K"
      },
      "source": [
        "#üîò exportarListaCompleta(texto para exportar1,texto para exportar2,texto para exportar3, nombre del nuevo archivo)\n",
        "exportarListaCompleta(texto_sin_stop,sustantivoss,texto_ya_lematizado,\"prueba2.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}