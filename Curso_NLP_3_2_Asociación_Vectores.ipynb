{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Curso NLP 3.2 Asociaci√≥n Vectores.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "VWDbPMU2LD3q",
        "J43afuf7zVtI",
        "a08npzYUzV-I",
        "-nVBY2Jy2VaV",
        "_JVrIttfrDuM",
        "g1cnbfMr13gR",
        "ABnEid_7zXP8",
        "7BxQxnGX3Q_D",
        "YTCf_ektHUwY",
        "KjSiPJxZbJe7"
      ],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armandovl/curso_nlp/blob/main/Curso_NLP_3_2_Asociaci%C3%B3n_Vectores.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIpZ10NnLEF0"
      },
      "source": [
        "<img src=\"https://i1.wp.com/www.sopitas.com/wp-content/uploads/2014/08/Tec-de-Monterrey-Logo-640x581.jpg\" width=\"70\"/> \n",
        "<h5>ITESM Campus Santa Fe<br> Armando Vald√©s </h5>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWDbPMU2LD3q"
      },
      "source": [
        "### Nomenclatura\n",
        "üü† Modificar <br>\n",
        "‚èÆ Repetir en caso de cambiar texto<br>\n",
        "üîò Opcional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J43afuf7zVtI"
      },
      "source": [
        "### 1.-Importar las bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7JXX8qozVtX"
      },
      "source": [
        "import nltk\n",
        "import gensim\n",
        "import matplotlib.pyplot as plt #importamos para graficos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRDYh79ZzVuf"
      },
      "source": [
        "nltk.download('punkt') #para tokenizar\n",
        "nltk.download('stopwords')#descargamos el complemento"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a08npzYUzV-I"
      },
      "source": [
        "### 2.-Leer el documento üü†"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3E67nYDOzV-J"
      },
      "source": [
        "with open ('malos_grano.txt',\n",
        "           'r',encoding='utf-8') as file:\n",
        "        document = file.read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aM5P3ZQzV-T"
      },
      "source": [
        "document[:1000] #üîò"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nVBY2Jy2VaV"
      },
      "source": [
        "### 3.-Preprocesar el documento ‚èÆ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JVrIttfrDuM"
      },
      "source": [
        "#### Tokenizar doumento ‚èÆ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-sFKJnqzV-f"
      },
      "source": [
        "# tokenizar el documento en oraciones ‚èÆ\n",
        "sentences = nltk.sent_tokenize(document)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UUopeW2jPv7"
      },
      "source": [
        "sentences[2] #ejemplo de oracion #üîò"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUUMIm6_zV-p"
      },
      "source": [
        "#tokenizar cada oracion en palabras ‚èÆ\n",
        "word_tokens = [nltk.tokenize.word_tokenize(sentence.lower()) for sentence in sentences]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5flSSFZWzXP1"
      },
      "source": [
        "word_tokens[2] #ejemplo de oracion tokenizada #üîò"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1cnbfMr13gR"
      },
      "source": [
        "#### Quitar Stop Words ‚èÆ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDOgFoK315vu"
      },
      "source": [
        "#Funcion Quitar Stop Words #ejecutamos la funcion\n",
        "def quitarStopWords(texto_para_quitar_stop_words):\n",
        "  from nltk.corpus import stopwords\n",
        "  salida_sin_stop_words = texto_para_quitar_stop_words[:]\n",
        "  for token in texto_para_quitar_stop_words:\n",
        "     if token in stopwords.words('spanish'):\n",
        "         salida_sin_stop_words.remove(token)\n",
        "  return(salida_sin_stop_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33O-D9PL21u4"
      },
      "source": [
        "extension_lista=len(word_tokens) #largo de la lista word_tokens ‚èÆ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcFsoiO52-F0"
      },
      "source": [
        "#funcion quitar stopwords en cada parte de la lista ‚èÆ\n",
        "word_tokens_sin_stop = []\n",
        "for i in range(extension_lista):\n",
        "  anadido=quitarStopWords(word_tokens[i])\n",
        "  word_tokens_sin_stop.append(anadido)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vu0kf1OR43Py"
      },
      "source": [
        "word_tokens[2] #üîò con stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnGsfCVa4oYi"
      },
      "source": [
        "word_tokens_sin_stop[2] #üîò sin stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABnEid_7zXP8"
      },
      "source": [
        "### 4.- Aplicar modelo üü† ‚èÆ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzQR1WeiKHrd"
      },
      "source": [
        "from gensim.models import Word2Vec #importamos Word2Vec de gensim para modelar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZOsvatlKLD3"
      },
      "source": [
        "'''\n",
        "#üîò #aplicamos el modelo r√°pido\n",
        "modelo07 = Word2Vec(sentences=word_tokens,\n",
        "                    size = 50,\n",
        "                    iter=100,\n",
        "                    min_count=2)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vgi3J1WpgfQ"
      },
      "source": [
        "#aplicamos el modelo completo ‚èÆ\n",
        "#parameters https://radimrehurek.com/gensim/models/word2vec.html\n",
        "modelo08 = Word2Vec(sentences=word_tokens_sin_stop, #fuente\n",
        "                  size=20, #Dimensionalidad de los vectores de palabras.\n",
        "                  min_count=3, #ignora todas las palabras con una frecuencia total inferior a esta.\n",
        "                  workers=15, #use estos hilos de trabajo para entrenar el modelo (= entrenamiento m√°s r√°pido con m√°quinas multin√∫cleo).\n",
        "                  window=4, #Distancia m√°xima entre la palabra actual y la pronosticada dentro de una oraci√≥n\n",
        "                  sg=1,#Algoritmo de entrenamiento: 1 para skip-gram; de lo contrario CBOW\n",
        "                  hs=1, #si es 1, se utilizar√° softmax jer√°rquico para el entrenamiento del modelo. Si 0 y negativo es distinto de cero, se utilizar√° un muestreo negativo.\n",
        "                  negative=0, #si> 0, se utilizar√° un muestreo negativo, el int para negativo especifica cu√°ntas \"palabras de ruido\" se deben dibujar (generalmente entre 5-20). Si se establece en 0, no se utiliza muestreo negativo.\n",
        "                  alpha=0.00001, # la tasa de aprendizaje inicial.\n",
        "                  iter=15000,# n√∫mero de iteraciones (√©pocas) sobre el corpus.\n",
        "                  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-wvTlj8f5se"
      },
      "source": [
        "modelo08.wv.most_similar(\"sabor\") #palabras m√°s cercanas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlFVg9UJlPgO"
      },
      "source": [
        "modelo08.wv.most_similar_cosmul(positive=['sabor','bastante'],negative=[',','.','!']) #palabras m√°s cercanas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXXA-T9UzXQL"
      },
      "source": [
        "#modelo08['caf√©'] #ver el vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BxQxnGX3Q_D"
      },
      "source": [
        "### 5.- Graficar palabras üü† ‚èÆ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BykSu9NPzXYi"
      },
      "source": [
        "from sklearn.decomposition import PCA #Para Graficar PCA functions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0qUmmtC9RBJ"
      },
      "source": [
        "'''\n",
        "#üîò Hacerlo a partir de un listado, Solo es opcional\n",
        "listado=[\"precio\",\"caf√©\",\"excelente\",\"nespresso\",\"sabor\"] #palabras a buscar en el modelo üü†\n",
        "modelo_aplicado=modelo08[listado]\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P61nU10m8i2b"
      },
      "source": [
        "# Transformar modelo 2d ‚èÆ\n",
        "#X = modelo_aplicado #solo para el modelo de la lista üîò\n",
        "X = modelo08[modelo08.wv.vocab] #transformamos todo el vocabulario del modelo\n",
        "pca = PCA(n_components=2) #lo reducimos a 2 dimensiones\n",
        "resultado = pca.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB3g3Ma6OnbW"
      },
      "source": [
        "# esto es lo que hay en el vocabulario del modelo‚èÆ\n",
        "etiqueta=list(modelo08.wv.vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQsOV9ssOtax"
      },
      "source": [
        "len(etiqueta) #extension del vocabulario"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9MPNuLb8z-h"
      },
      "source": [
        "# create a plot of the projection ‚èÆ\n",
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(8, 7)\n",
        "ax.plot(resultado[:, 0], resultado[:, 1], 'x')\n",
        "ax.set_title('Encabezado')\n",
        "\n",
        "#poner las etiquetas\n",
        "'''\n",
        "words = list(modelo08.wv.vocab)\n",
        "for i, word in enumerate(words):\n",
        "    plt.annotate(word, xy=(resultado[i, 0],resultado[i, 1]))\n",
        "'''\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTCf_ektHUwY"
      },
      "source": [
        "### 6.-Exportar para graficar  üîò‚èÆ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtoeQgMnGagS"
      },
      "source": [
        "#‚èÆ\n",
        "import pandas as pd    \n",
        "df = pd.DataFrame(resultado) #convertimos en un Data Frame\n",
        "df.columns = [\"valorx\", \"valory\"] #Agregamos t√≠tulos a las columnas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBHjrp1xG1as"
      },
      "source": [
        "#‚èÆ\n",
        "#df['palabra'] = listado #para el ejemplo de la lista\n",
        "df['palabra'] = etiqueta #Agregamos columnas con etiquetas "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opxxLwp6GgEz"
      },
      "source": [
        "df.head(10) #vemos como quedar√≠a üîò"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYH-svZdG1YP"
      },
      "source": [
        "#‚èÆ\n",
        "df.to_csv('nombre2.csv', index=False) #exportamos a CSV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FC4y7RfYKz8"
      },
      "source": [
        "#‚èÆ Exportar a TSV\n",
        "df.to_csv('tres_dimensiones.tsv', sep = '\\t', index=False) #exportamos a tsv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9UGf_4Oo_Vl"
      },
      "source": [
        "Recomendable!! checar los de mayor frecuencia y buscar las palabras cercanas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AARi-T18pDM0"
      },
      "source": [
        "modelo08.wv.most_similar(\"aroma\") #palabras m√°s cercanas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjSiPJxZbJe7"
      },
      "source": [
        "### 7.- Exta üü†\n",
        "Modelo desde un archivo de texto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7NLqHBpS5XY"
      },
      "source": [
        "#importamos Word2Vec de gensim para modelar\n",
        "#si ya est√°, ya no se necesita\n",
        "from gensim.models import Word2Vec "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CovnLBCebKpW"
      },
      "source": [
        "#parameters https://radimrehurek.com/gensim/models/word2vec.html\n",
        "modelo = Word2Vec(corpus_file=\"buenos_soluble.txt\", #sentences=word_tokens,\n",
        "                  size=20, #Dimensionalidad de los vectores de palabras.\n",
        "                  min_count=2, #ignora todas las palabras con una frecuencia total inferior a esta.\n",
        "                  workers=10, #use estos hilos de trabajo para entrenar el modelo (= entrenamiento m√°s r√°pido con m√°quinas multin√∫cleo).\n",
        "                  window=3, #Distancia m√°xima entre la palabra actual y la pronosticada dentro de una oraci√≥n\n",
        "                  sg=1,#Algoritmo de entrenamiento: 1 para skip-gram; de lo contrario CBOW\n",
        "                  hs=1, #si es 1, se utilizar√° softmax jer√°rquico para el entrenamiento del modelo. Si 0 y negativo es distinto de cero, se utilizar√° un muestreo negativo.\n",
        "                  negative=0, #si> 0, se utilizar√° un muestreo negativo, el int para negativo especifica cu√°ntas \"palabras de ruido\" se deben dibujar (generalmente entre 5-20). Si se establece en 0, no se utiliza muestreo negativo.\n",
        "                  alpha=0.00001, # la tasa de aprendizaje inicial.\n",
        "                  iter=1000,# n√∫mero de iteraciones (√©pocas) sobre el corpus.\n",
        "                  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZ4wseMAmYeE"
      },
      "source": [
        "modelo.wv.most_similar(\"llega\") #palabras mpas cercanas"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}