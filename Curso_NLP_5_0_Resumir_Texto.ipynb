{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Curso NLP 5.0 Resumir Texto",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vvJEm6pVfjvZ"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armandovl/curso_nlp/blob/main/Curso_NLP_5_0_Resumir_Texto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3s87wMzdTO_x"
      },
      "source": [
        "pip install inscriptis #esta librería se tiene que instalar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYIgqJUuSOVy"
      },
      "source": [
        "#importamos librerias\n",
        "#https://inteligencia-artificial.dev/resumen-textos-python/\n",
        "#https://www.youtube.com/watch?v=So4kBtUe-HY\n",
        "#queda pendiente : https://www.instintoprogramador.com.mx/2019/07/resumen-de-texto-con-nltk-en-python.html\n",
        "\n",
        "import bs4 as bs  \n",
        "import urllib.request  \n",
        "import re\n",
        "import nltk\n",
        "import bs4\n",
        "import urllib.request\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import urllib.request\n",
        "from inscriptis import get_text\n",
        "from nltk import word_tokenize,sent_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1WdcsEvUqDF"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5OLtFbXgDUQ"
      },
      "source": [
        "#1#\n",
        "#lo primero que hacemos es importar el archivo de texto, en r de reescribir\n",
        "archivo=open(\"malos_capsulas.txt\",\"r\")\n",
        "article_text=archivo.read() #el texto del txt se queda en la variable texto_del_archivo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "At0Ir-EUUc8_"
      },
      "source": [
        "#Eliminación de corchetes y espacios adicionales\n",
        "article_text = re.sub(r'\\[[0-9]*\\]', ' ', article_text)  \n",
        "article_text = re.sub(r'\\s+', ' ', article_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xO5muBtWUfCf"
      },
      "source": [
        "formatted_article_text = re.sub('[^a-zA-Z]', ' ', article_text )  \n",
        "formatted_article_text = re.sub(r'\\s+', ' ', formatted_article_text)  \n",
        "#EN ESTA PARTE HACE LA TOKENIZACION \n",
        "sentence_list = nltk.sent_tokenize(article_text) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDgElIk2Uxde"
      },
      "source": [
        "#EN ESTA PARTE ENCUENTRA LA FRECUENCIA DE CADA PALABRA\n",
        "stopwords = nltk.corpus.stopwords.words('spanish')\n",
        " \n",
        "word_frequencies = {}  \n",
        "for word in nltk.word_tokenize(formatted_article_text):  \n",
        "    if word not in stopwords:\n",
        "        if word not in word_frequencies.keys():\n",
        "            word_frequencies[word] = 1\n",
        "        else:\n",
        "            word_frequencies[word] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leX1xvMIVGVm"
      },
      "source": [
        "maximum_frequncy = max(word_frequencies.values())\n",
        " \n",
        "for word in word_frequencies.keys():  \n",
        "    word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1V_43piVIUK"
      },
      "source": [
        "#CALCULA LAS FRASES QUE MÁS SE REPITEN\n",
        "sentence_scores = {}  \n",
        "for sent in sentence_list:  \n",
        "    for word in nltk.word_tokenize(sent.lower()):\n",
        "        if word in word_frequencies.keys():\n",
        "            if len(sent.split(' ')) < 30:\n",
        "                if sent not in sentence_scores.keys():\n",
        "                    sentence_scores[sent] = word_frequencies[word]\n",
        "                else:\n",
        "                    sentence_scores[sent] += word_frequencies[word]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME3xnXN9VNVF"
      },
      "source": [
        "#REALIZA EL RESUMEN CON LAS MEJORES FRASES\n",
        "import heapq  \n",
        "summary_sentences = heapq.nlargest(10, sentence_scores, key=sentence_scores.get)\n",
        " \n",
        "summary = '\\n '.join(summary_sentences)  \n",
        "print(summary)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvJEm6pVfjvZ"
      },
      "source": [
        "### Para Traducir el texto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3lMHJLZb_jv"
      },
      "source": [
        "pip install google_trans_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMOPap94dfQJ"
      },
      "source": [
        "from google_trans_new import google_translator  \n",
        "  \n",
        "translator = google_translator()  \n",
        "translate_text = translator.translate(summary,lang_src='en',lang_tgt='es-mx')  \n",
        "print(translate_text)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}